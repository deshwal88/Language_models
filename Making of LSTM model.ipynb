{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "upset-bobby",
   "metadata": {},
   "source": [
    "### Required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "approximate-yellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as keras\n",
    "import reader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-ethernet",
   "metadata": {},
   "source": [
    "The module reader is my user-defined module containing functions to build vocabulary, read files and converting words to id and vice versa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-bulletin",
   "metadata": {},
   "source": [
    "### Reading data and building vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cordless-poultry",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=reader.read('ptb.train.txt','../Datasets ML/simple-examples/data')\n",
    "valid=reader.read('ptb.valid.txt','../Datasets ML/simple-examples/data')\n",
    "test=reader.read('ptb.test.txt','../Datasets ML/simple-examples/data')\n",
    "vocab=reader.build_vocab('ptb.train.txt','../Datasets ML/simple-examples/data')\n",
    "vocab_size=len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-control",
   "metadata": {},
   "source": [
    "The function getdata converts data files into training and validation set with provided timesteps. <br>\n",
    "Shape of each data point is  (1,timesteps,1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "designed-ranch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdata(data,time_steps):\n",
    "    data=reader.word_to_id(data,vocab)\n",
    "    size=len(data)\n",
    "    epochs=(size-1)//time_steps\n",
    "    x=np.zeros((epochs,time_steps),dtype=int)\n",
    "    y=np.zeros((epochs,time_steps),dtype=int)\n",
    "    for i in range(0,epochs):\n",
    "        x[i,:]=data[i*time_steps:(i+1)*time_steps]\n",
    "        y[i,:]=data[i*time_steps+1:(i+1)*time_steps+1]\n",
    "        \n",
    "    x=x.reshape((-1,time_steps,1))\n",
    "    y=y.reshape((-1,time_steps,1))\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ideal-grill",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_trn,y_data_trn=getdata(train,30)\n",
    "x_data_val,y_data_val=getdata(train,30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-greensboro",
   "metadata": {},
   "source": [
    "### Building model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-exposure",
   "metadata": {},
   "source": [
    "Now, we will build a stacked LSTM model using two LSTM cells and bind them using RNN layer in Keras. For better and stable learning we will use Batch Normalization layer. At last we will use Time Distributed layer to apply the activation function at each time step as our model will return sequence i.e. return output at each time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "innocent-gravity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 30)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 30, 500)           5000000   \n",
      "_________________________________________________________________\n",
      "rnn (RNN)                    (None, 30, 500)           4004000   \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 30, 500)           2000      \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 30, 10000)         5010000   \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 30, 10000)         0         \n",
      "=================================================================\n",
      "Total params: 14,016,000\n",
      "Trainable params: 14,015,000\n",
      "Non-trainable params: 1,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp=keras.Input(shape=(30,))\n",
    "embedding=keras.layers.Embedding(vocab_size,500,input_length=30)\n",
    "x=embedding(inp)\n",
    "\n",
    "l1=keras.layers.LSTMCell(500)\n",
    "l2=keras.layers.LSTMCell(500)\n",
    "rnn_stacked=keras.layers.StackedRNNCells([l1,l2])\n",
    "rnn=keras.layers.RNN(rnn_stacked,return_sequences=True)\n",
    "x=rnn(x)\n",
    "\n",
    "norm=keras.layers.BatchNormalization()\n",
    "x=norm(x)\n",
    "\n",
    "dense=keras.layers.Dense(vocab_size)\n",
    "td=keras.layers.TimeDistributed(dense)\n",
    "x=td(x)\n",
    "\n",
    "activation=keras.layers.Activation('softmax')\n",
    "out=activation(x)\n",
    "\n",
    "model=keras.Model(inp,out)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-methodology",
   "metadata": {},
   "source": [
    "Now, we are all set to train our LSTM model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-organ",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-likelihood",
   "metadata": {},
   "source": [
    "For faster training process we will use GPU instead of CPU with batch size of 20. Language models are very slow in case of training. They would need atleast 40 epochs to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sufficient-edinburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    model.fit(x_data_trn, y_data_trn, batch_size=20, epochs=40, validation_data=(x_data_val,y_data_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-albuquerque",
   "metadata": {},
   "source": [
    "### Saving and loading model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reverse-order",
   "metadata": {},
   "source": [
    "Instead of saving model as H5 we will save model weights and parameters separately as it would consume very less space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-manner",
   "metadata": {},
   "source": [
    "> Saving model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sophisticated-picture",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./weights.h5',save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "human-billion",
   "metadata": {},
   "outputs": [],
   "source": [
    "string=model.to_json()\n",
    "with open('./model_config.json','w') as file:\n",
    "    file.write(string)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-footwear",
   "metadata": {},
   "source": [
    "> Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "irish-trunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./model_config.json','r') as file:\n",
    "    config=file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "experienced-building",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded=keras.models.model_from_json(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "expected-nashville",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 30)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 30, 500)           5000000   \n",
      "_________________________________________________________________\n",
      "rnn (RNN)                    (None, 30, 500)           4004000   \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 30, 500)           2000      \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 30, 10000)         5010000   \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 30, 10000)         0         \n",
      "=================================================================\n",
      "Total params: 14,016,000\n",
      "Trainable params: 14,015,000\n",
      "Non-trainable params: 1,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "refined-drove",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded.load_weights('./weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passing-newman",
   "metadata": {},
   "source": [
    "Voila!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complex-director",
   "metadata": {},
   "source": [
    "### Testing model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-pakistan",
   "metadata": {},
   "source": [
    "Now, we come to the testing part. How our model performs to a random input by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cultural-annotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./vocab.json','r') as file:\n",
    "    vocab=file.read()\n",
    "file.close()\n",
    "vocab=json.loads(vocab)\n",
    "\n",
    "context='Despite the fact that tea has been popular in the UK for hundreds of years, the question of when to add the milk \\\n",
    "        is one which still provokes many an argument'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-click",
   "metadata": {},
   "source": [
    "Defining a predicting function to predict specific number of words given the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "coordinated-french",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(context,time_steps,num):\n",
    "    words=context.replace('.',' <eos>').split()\n",
    "    for i in range(0,num):\n",
    "        inp=words[-time_steps:]\n",
    "        inp=reader.word_to_id(inp,vocab)\n",
    "        inp=np.reshape(inp,(1,time_steps,1))\n",
    "        out=model.predict(inp)\n",
    "        out=np.argmax(out,axis=2)[0]\n",
    "        results=reader.id_to_word(out,vocab)\n",
    "        words.append(results[-1])\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-theater",
   "metadata": {},
   "source": [
    "Checking results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "alone-argentina",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Despite the fact that tea has been popular in the UK for hundreds of years, the question of when to add the milk is one which still provokes many an argument against baker boys it\n"
     ]
    }
   ],
   "source": [
    "results=predict(context,30,4)\n",
    "print(' '.join(results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
